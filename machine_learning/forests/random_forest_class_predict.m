function [y_fit votes y_all_trees proximities] = random_forest_class_predict(forest, X, tree_mask, use_probs)
%RANDOM_FOREST_CLASS_PREDICT given a random forest and input data,
%predict the set of class labels for the data
%   [random_forest] = random_forest_class_predict(forest, X)
%
%   X:      N x d matrix of input data, where each row is a
%           datapoint consisting of d input variables
%
%   forest: Random forest structure as generated by
%   RANDOM_FOREST_CLASS_TRAIN
%
% Outputs:
%   y_fit:  Set of class labels predicted for each data point (note these
%           are currently returned as text labels in an Nx1 cell string
%           array. To convert to numeric values call str2double(y_fit),
%           which will produce an Nx1 vector of equivalent numeric values
%
%   votes:  Votes for each class for each data point (note by dividing by
%           the number of trees in the forest these can be used to
%           constructed output probabilities (as opposed to hard labels)
%
% Example:
%
% Notes:
%
% See also: RANDOM_FOREST_CLASS_TRAIN TREE_PREDICT
%
% Created: 13-Oct-2009
% Author: Michael Berks 
% Email : michael.berks@postgrad.man.ac.uk 
% Phone : +44 (0)161 275 1241 
% Copyright: (C) University of Manchester
if nargin < 3
    tree_mask = [];
end
if nargin < 4
    use_probs = 0;
end

%workout number of data points and input variables
N = size(X, 1);

%Work out number of trees in forest and number of output classes
n_trees = length(forest.trees);
nclasses = forest.nclasses;
    
%pre-allocate space for class votes from each tree
votes = zeros(N, nclasses);

%Set up tree mask that will select which trees vote for which points (e.g.
%used to compute out-of-bag errors on training data)
if isempty(tree_mask)
    tree_mask = true(N, n_trees);
else
    tree_mask = ~full(tree_mask);
end

if nargout > 2
    y_all_trees = zeros(N, nclasses, n_trees);
end
if nargout > 3
    proximities = zeros(N);
end

%Check if trees are preloaded
if isstruct(forest.trees{1})
    trees_loaded = true;
elseif ischar(forest.trees{1})
    trees_loaded = false;
else
    error(['Incorrect datatype for trees. Must either be a struct containing the tree itself',...
        ' or a string containg the filepath to the tree on disk']);
end

for ii = 1:n_trees

    %load tree
    if trees_loaded
        tree = forest.trees{ii};
    else
        tree = u_load([forest.tree_root forest.tree_dir forest.trees{ii}]);
    end
    
    %Get predictions for data from this tree
    [y_tree nodes] = tree_predict(tree, X, use_probs);
    
    %Assign votes for each class
    if use_probs
        votes = votes + y_tree;
        if nargout > 2
            y_all_trees(:,:,ii) = y_tree;
        end
    else
        for jj = 1:nclasses
            
            
            if isnumeric(y_tree)
                votes_ij = tree_mask(:,ii) .* (y_tree(:) == forest.classname(jj));
            elseif iscellstr(y_tree)
                votes_ij = tree_mask(:,ii) .*  strcmp(y_tree(:), forest.classname(jj));
            else
                error('Type predictions from tree should be numeric or a cell of strings');
            end  
            
            votes(:, jj) = votes(:, jj) + votes_ij;
            
            if nargout > 2
                y_all_trees(:,jj,ii) = votes_ij;
            end
        end
    end
    
    if nargout > 3
    %Compute proximity measure - i.e. count the number of times data points
    %end up at the same leaf node
        leaf_nodes = unique(nodes);
        for jj = 1:length(leaf_nodes)
            leaf = leaf_nodes(jj);
            leaf_pts = double(nodes == leaf);
            proximities = proximities + (leaf_pts * leaf_pts');
        end
    end   
end

%Get index to class with maximum votes
[dummy y_idx] = max(votes, [], 2); clear dummy

%Convert class index to class labels and compute error rate
y_fit = forest.classname(y_idx);

%If we need to calculate proximities, divide by n_trees to get measure
%between 0 and 1
if nargout > 3
    proximities = proximities / n_trees;
end
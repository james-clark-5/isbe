The classification and regression forests were then used to compute a line detection score (the proportion of votes for the curvilinear structure class) at each pixel. 

In addition to the four learning methods, the prescriptive variants of the Monogenic, Linop and Gaussian approaches were applied to the test images (\ref{f:synthetic_responses}).

ROC curves for the seven methods tested are shown in~\ref{f:}, using the known ground-truth for the test images to define pixels on the centrelines of curvilinear structures as foreground, and pixels lying outside the structures as background. Areas under the ROC curves and detection sensitivities at a fixed specificity of 90\% are shown in~\ref{t:}.

As expected, because Linop, of the three prescriptive methods, discards the highest proportion of filter responses, Linop/RF gains the most from training. This highlights the ability of the random forests to extract useful information from a rich local description of image content, and whilst we do not have a prescriptive variant to compare it to, we believe this shows the importance of training in maximizing the benefit of using the \dtcwt{}. 

We also note that the added information that can be gained from the \dtcwt{} representation results from an increase in the richness of the local description of texture and is not due to increasing the support of the descriptor. Indeed, as described above we tested all representations over an equivalent range of filter scales so that the same image support was available to each method.

%\input{tab_ipmi_detection_orientation.tex}

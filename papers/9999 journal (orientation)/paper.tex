%\documentclass[a4paper]{article}
\documentclass{IEEEtran}

%\usepackage{times}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}

% Any macro definitions you would like to include
% These are not defined in the style file, because they don't begin
% with \bmva, so they might conflict with the user's own macros.
% The \bmvaOneDot macro adds a full stop unless there is one in the
% text already.
\def\eg{\emph{e.g.,}}
\def\ie{\emph{i.e.,}}
\def\etal{\emph{et al.}}
\def\vs{\emph{vs.}}

% macros for referencing figures, tables, equations and sections
\newcommand{\fref}[1]{Figure~\ref{#1}}
\newcommand{\eref}[1]{(\ref{#1})}
\newcommand{\tref}[1]{Table~\ref{#1}}
\newcommand{\sref}[1]{Section~\ref{#1}}
\newcommand{\aref}[1]{Algorithm~\ref{#1}}
\newcommand{\emptybox}[2]{\framebox[#1][l]{\rule[#2]{0pt}{0pt}}}

% maths macros
\def\G{G}
\def\Gx{G_x}
\def\Gy{G_y}
\def\Gxx{G_{xx}}
\def\Gxy{G_{xy}} \def\Gyx{G_{yx}}
\def\Gyy{G_{yy}}
\def\Ix{I_x}
\def\Iy{I_y}
\def\Ixsqr{I_{x^2}}
\def\Iysqr{I_{y^2}}
\def\Ixx{I_{xx}}
\def\Ixy{I_{xy}}
\def\Iyy{I_{yy}}
\def\dtcwt{DT-$\mathbb{C}$WT}

\def\deg{\ensuremath{^\circ}}
\def\rad{\ensuremath{\text{radians}}}
\def\by{\ensuremath{\times}}

% lengths for image sizes
\newlength{\qtrcol}\setlength{\qtrcol}{0.24\columnwidth}
\newlength{\halfcol}\setlength{\halfcol}{0.48\columnwidth}

% command for adding inline comment to text
\newcommand{\comment}[1]{}

% define title here so headers are updated, too
\def\ttl{Analysing Curvilinear Structures in Images}
\title{\ttl}
\author{Authors}

% define path to figures
\def\figroot{./figs}
\def\figpath{\figroot}


%-------------------------------------------------------------------------
% Document starts here
\begin{document}

\tableofcontents\clearpage

\maketitle

\begin{abstract}
Estimating orientation of image structure underpins applications including digital mammography, retinography and fingerprint analysis. We consider different choices of filter bank including those based on first and second derivatives, efficient Haar-like features and the Dual Tree Complex Wavelet Transform. We then investigate how standard regressors (linear regression, Boosting and Random Forests) may be adapted to use the responses to these filter banks in order to predict orientation of image structure. For a quantitative evaluation, we use synthetic images based on mammograms and the publicly available DRIVE database of retinal images, and show that Random Forests and the wavelet transform offer superior accuracy though at a cost in efficiency. Qualitative results are also presented for real mammograms and fingerprint images.
\end{abstract}

\input{citations.tex}


\section{Introduction}
% State the problem, and its impact on all stakeholders (those directly affected, and society at large e.g. the social and economic impact of treating the disease)
A curvilinear structure in an image appears as a ribbon or bar of finite width that is distinguishable from the surrounding structure, with a cross-sectional profile that is repeated along a linear, though not necessarily straight, path (\fref{f:line_examples}).

%What are their general characteristics?
%Defined locally by their cross-sectional profile and orientation, and assumed to extend in at least one direction normal to the profile (as opposed to a blob).

Detecting and measuring the properties of curvilinear structures in images is useful for many reasons~\cite{Ayres_Rangayyan_JEI07}:

\begin{itemize}
\item detecting distinctive patterns of vessels and fibrous tissue can improve quality of life and reduce costs associated with treating diseases such as retinopathy (\sref{s:retinopathy}) and breast cancer (\sref{s:mammography}) in advanced stages by aiding early diagnosis and treatment; %
\item spotting cracks and other similar defects in manufactured items such as roads, eggs can reduce costs associated with waste; %
\item biometrics based on ridge patterns in fingerprints~\cite{}, or the veins of the finger~\cite{} or hand~\cite{}, can bring criminals to justice and prevent further crime, or enhance the usability of technology by controlling access to sensitive data; %
\item detecting roads, railways and rivers in aerial photography can help to build maps automatically for applications such as providing relief in remote areas following a natural disaster.
\end{itemize}


\subsection{Aims and Objectives}
% Specific aims of the study
Given an image, our aim is to determine where any linear structures exist in the image, and to measure values that correspond to low-level properties such as orientation, width, and cross-sectional profile. Although these properties form the basis of higher level, application-specific analysis (classifying structure as \emph{road}, \emph{rail} or \emph{river} in aerial photographs, for example), our focus is purely on computing the local attributes as accurately and robustly as possible; by improving the accuracy of the values we estimate, it follows logically that performance should improve for all higher level analysis methods that use these values as inputs.\footnote{Any algorithm that does not benefit from better input should be regarded with suspicion.}

%For example, any method to move from a map of vessel probabilities and predicted orientations in a retinograms, to an explicit grouping of pixels that belong to individual vessels, is likely to benefit from a priori knowledge of the spatial arrangement vessels in that image class and the physical model of how vessels grow and bifurcate. Such a method will therefore be very different from that needed to group a similar set of local information into the road, rivers etc present in an image for aerial analysis

With this focus, we have two objectives: extract, at every image location, structural information that is rich enough to capture the underlying image properties yet sparse enough to be computed efficiently; and combine this raw local information to predict output values of interest (such as orientation).


% Review other people's attempts at solving the problem, and why they are found wanting
\subsection{Related Work}
\input{related_work}

% Describe what we do, and why it is better than preceding works
\subsection{Our Contributions}
\input{our_contributions}




\clearpage
\section{Input Image Features}
\label{s:filtering}
To predict some quantity of interest (such as line orientation or the probability of linear structure) from a sample image patch, it is useful first to reduce the high-dimensional image data to a more compact feature vector that captures the most important properties of the image yet discards redundant information. This improves the performance of statistical pattern recognition algorithms by reducing the effects of the `curse of dimensionality'~\cite{Bellman} whereby the number of training examples required for a given sampling density increases exponentially with input dimensionality.

%Other approaches to detecting linear structure in mammograms include using second derivatives of the mammographic image surface~\cite{Cerneaz_Brady_CVVRRM95} or second derivatives of the 2D Gaussian~\cite{Karssemeijer_teBrake_TMI96}

% Summary: template matching is pretty pants - you only get a strong response if you have the template at the correct location, orientation and scale; steerable filters give you a strong response at the correct location and scale, but orientation can be interpolated from a small number of filters; gabor filters give a strong response at the correct orientation and scale, but can interpolate over small displacements, making them less sensitive to location; the dtcwt can be seen as an efficient approximation to Gabor filters in that must be applied at the correct scale and orientation but uses phase to make it insensitive to displacements. (Can the DTCWT interpolate over orientation, too?)

\subsection{Template Matching}
Template matching approaches take a template that resembles the object of interest, and convolve it with the image at several scales and orientations. A discretized translation, scale and orientation can then be found from local maxima of the filter responses in the four-dimensional parameter space.

\input{methods/image_processing/filtering_linop.tex}%

Though straightforward to implement, template matching is computationally inefficient due to the need to apply the template at many discrete orientations. Though the number of orientations can be reduced, this reduces the accuracy of the orientation estimate.

\subsection{Steerable Filters}
Applying many filters at discrete orientations can be avoided by using \emph{steerable} filters~\cite{Freeman_Adelson_TPAMI91,Koenderink_vanDoorn_TPAMI92}, where the response to a filter at any angle can be computed as a function of the response to the filter at a small and fixed number of orientations. Not only does this provide almost arbitrary accuracy for a fixed number of oriented basis filters, but the basis filters are frequently \emph{separable}, making the convolution itself more efficient. Here we consider two popular choices: first- and second-order derivatives of the Gaussian.

\subsubsection{First order derivatives}
\input{methods/image_processing/filtering_first_derivs.tex}%

%\subsubsection{Squared responses}
%\input{methods/image_processing/filtering_squared_responses.tex}%
%
\subsubsection{Second derivatives}
\input{methods/image_processing/filtering_second_derivs.tex}%

\comment{Haar-like approximations are not as new as I first hoped - they are the basis of the SURF feature descriptor, and Peter Kovesi also wrote a paper explaining why even this is not the most efficient thing to do. I've removed it until we can justify having it in.}
%\subsection{Haar-like Approximations}
%\input{methods/image_processing/filtering_haar.tex}%

\subsection{Incorporating Phase}
Because first-order derivatives perform well at edges but poorly at the centre of a line, and second-order derivatives have the opposite characteristics, it is sensible to combine their strengths by using both odd and even filters. Ideally, this would be achieved using a Hilbert Transform pair of filters that are $90\deg$ out of phase, though in practice an approximation is often sufficient~\cite{Freeman_Adelson_TPAMI91}. Information on the \emph{phase} offset of the image feature then becomes available, which can be used to describe the local shape of the linear feature and provide invariance to small displacements from the line centre when estimating orientation.

%Researchers have recognised the importance of using local phase information to distinguish between strong edges and genuine curvilinear structure. In mammography, examples include Gabor filters~\cite{Rangayyan_Ayres_MBEC06} and other sets of complex filters~\cite{Schenk_Brady_IWDM02,McLoughlin_etal_SPIE02} that were also steerable~\cite{Freeman_Adelson_TPAMI91}, at multiple scales to compute local energy, orientation and phase at each pixel. 

%One further study used the `monogenic' signal~\cite{Wai_etal_MICCAI04} as a more efficient way of calculating local phase and orientation at multiple scales, detecting curvilinear structure using amplitude-weighted local phase congruency.

Here we consider three approaches that combine the strengths of odd and even filters: the monogenic signal; Gabor wavelets~\cite{Daugman_TASSP88}; and the Dual Tree Complex Wavelet Transform (\dtcwt{}~\cite{Kingsbury_PTRSLA99}), so far unexploited in applications analysing curvilinear structure.

\subsubsection{The Monogenic Signal}
\input{methods/image_processing/filtering_monogenic.tex}%
The monogenic signal therefore suffers from the same weakness as a first-order derivative filter.

\subsubsection{Gabor Filters}
\input{methods/image_processing/filtering_gabor.tex}%
Gabor filters therefore impose a similar computational burden to template matching methods.

\subsubsection{The Dual Tree Complex Wavelet Transform (\dtcwt{})}
\input{methods/image_processing/filtering_dtcwt.tex}%

% How we use the DTCWT in this work
It is not clear, however, how to use responses to the \dtcwt{} filters to compute a single measure of curvilinear structure probability. Though we could select the maximum of the six oriented sub-band coefficients at each scale and combine them in a measure of phase congruency (as in a method based on the monogenic signal~\cite{Wai_etal_MICCAI04}), this would discard potentially useful information.

We therefore construct a feature vector that characterises each pixel by sampling \dtcwt{} coefficients from the six oriented sub-bands in each of the $s$ finest decomposition scales from a neighbourhood centred on the pixel, and transforming every complex response, $c$, to polar coordinates (\ie~magnitude, $|c|$, and angle, $\angle c$). Since orientation is only defined up to a rotation of $180^\circ$, however, the sign of the angle is arbitrary and so we use its absolute value, $|\angle c|$.
%a point with phase $\phi$ displaced by $d$ from the centre of a line is indistinguishable from a point with phase $-\phi$ displaced by $-d$ from the same line when looking in the opposite direction

\subsection{Pooling over scales}
Curvilinear structures of different sizes may appear in the image (\eg~from fine spicules to thick ducts in mammograms), and therefore it is necessary to filter the image at several scales to capture all structures~\cite{Lindeberg_IJCV98b}. We achieve this either by scaling the filters (as in the first- and second-order derivatives, Gabor filters, and the monogenic signal), or by keeping the filters fixed and scaling the image (as in the \dtcwt{} where the image is downsampled at every level of a pyramid).

\comment{This is only relevant to orientation}
Having obtained responses at several scales, we must decide how best to combine them into a single estimate of orientation. One option is to discard all scales but that with the strongest overall response~\cite{Karssemeijer_teBrake_TMI96}, using the responses from the discrete orientations only at the selected scale to determine orientation analytically.

% Interpolation? Would need to determine an interpolation function. An interesting problem in itself...

In this work, we compare this analytical approach to an alternative whereby we use the responses at all scales as input to a regressor that predicts the orientation directly. In addition to being a general purpose approach that is independent of the input features, this has the added advantage that it can be applied for filter banks such as the \dtcwt{} where an analytic solution is not obvious.

\subsection{Pooling over space}
We compute filter responses at all pixels within a neighbourhood and concatenate the resulting feature vectors. This has the effect of...

% Computational efficiency?
%\input{filtering_computation.tex}%


\clearpage
\section{Target Output Labels}
Our approach to analyzing and understanding images containing linear structure is to use statistical learning methods to recognize patterns present in training data in order to predict useful information in previously unseen images. More specifically, we focus on three tasks: detecting linear structures in the image; discriminating between linear structures of different types (\eg~classifying ducts from spicules in mammograms); and measuring the orientation of linear structures. Though the input image features are common across all three tasks, the output label we wish to predict is task-dependent.

\subsection{Detecting Linear Structure}
\input{why/detect_lines/in_general}
\input{output_labels/label_detection}%

\subsection{Classifying Linear Structure}
\input{why/classify_lines/in_general}%
\input{why/classify_lines/in_mammograms}%
\input{output_labels/label_classification}%

\subsection{Measuring Orientation}
\label{s:measuring_orientation}
\input{why/measure_orientation/in_general}%
To address this problem, we assume that orientation can be expressed as a (typically nonlinear) function of the responses to a given set of filters. Theoretically, we know this to be true for some filter banks (\eg~second derivatives of a Gaussian), though there are some complications. 

First, when filters are applied at more than one scale we must ensure that we use the responses from the best scale for the true line width; analytic methods~\cite{Karssemeijer_teBrake_TMI96,Mei_etal_IVC09} assume this is the scale with the greatest response, though this is not guaranteed in the presence of noise. Second, any analytic method that assumes noise to be additive and Gaussian may suffer when this is not the case; this is a particularly a risk in medical applications (\eg~ultrasound has multiplicative Rayleigh noise). Third, for some filter banks (such as the \dtcwt{}) an analytic solution is not available at all or is fiendishly complex at best.

\input{output_labels/label_orientation}


\clearpage
\section{Statistical Learning Methods}
Given a set of filter-bank outputs from different scales, the second step in estimating orientation is to combine them in some way. There are two basic approaches: to find the scale at which the total magnitude of response is greatest, and combine the different filter responses at that scale analytically~\cite{Karssemeijer_teBrake_TMI96,Mei_etal_IVC09}; or to use a regression learning approach to combine the filter responses across all scales and orientations~\cite{Berks_etal_IPMI11}.

In this work, we consider three classifiers of varying complexity: a linear classifier; a boosted classifier; and a Random Forest.

\subsection{Linear Classification}
\label{s:learning_linear}
\input{methods/machine_learning/linear_regression/regression_linear.tex}

%\subsection{Logistic Classification}
%\label{s:learning_logistic}
%\input{regression_logistic}

\subsection{Boosted Learning}
\label{s:learning_boosted}
\input{methods/machine_learning/boosting/regression_boosted.tex}%

\subsection{Random Forests}
\label{s:learning_forest}
\input{methods/machine_learning/decision_trees/rf_tree.tex}
\input{methods/machine_learning/random_forests/rf_background.tex}
\input{methods/machine_learning/random_forests/rf_detection.tex}
\input{methods/machine_learning/random_forests/rf_orientation.tex}%

Considering that curvilinear structure has a well-defined orientation, the confidence in an orientation estimate can also be used as a substitute for detection.


\clearpage
\section{Quantitative Evaluations}
[Results of experiments on synthetic data go here.]


\clearpage
\section{Application: Retinography}
\label{s:app_retinography}
\input{what_is/diabetic_retinopathy}

\input{why/detect_lines/in_retinograms}

\input{why/measure_orientation/in_retinograms}

% Introduction to the experiments and common properties
% Points that are common to all retinogram experiments

\label{s:exp_retinogram}
In the following experiments, we detect vessels and estimate their orientation from retinograms using a variety of filter banks and statistical regression methods. We compare performance between different filter-regressor combinations, and also compare our best results with current state of the art.

\subsection{Dataset}
\input{datasets/dataset_drive.tex}

\subsection{System Parameters}
% which features do we consider
Real and imaginary \dtcwt{} coefficients were computed across all six subbands (\ie~basis filter orientations) at the first five scales of the image pyramid, giving a $60D$ feature vector at each pixel. We also pooled information over the local $3 \by 3$ neighbourhood to give a $540D$ feature vector at each pixel.

To provide a baseline comparison for orientation estimation we filtered the images with Gaussian derivatives $\Gxx$, $\Gyy$ and $\Gxy$ at scales of $\sigma{=}[0.5, 1, 2, 4, 8]$ and solved~\eref{e:r2s} to determine analytically the orientation that maximised the response over all scales. 

Every Random Forest contained 200 trees to follow published guidelines~\cite{Breiman_ML01} and was pruned such that the variance at each leaf was approximately $5\%$ of the total variance in the data.

\subsection{Detecting Vessels}
\input{experiments/detecting_lines/in_retinograms/exp_retinogram_detection.tex}

\subsection{Estimating Orientation}
\input{experiments/measuring_orientation/in_retinograms/exp_retinogram_orientation.tex}


\clearpage
\section{Application: Mammography}
\input{what_is/breast_cancer}

\subsection{Datasets}
\subsubsection{Real Mammograms}
\input{datasets/dataset_realmamm}

\subsubsection{Synthetic Mammogram-like Images}
\input{datasets/dataset_synthmamm}

\subsection{System Parameters}
During training, we synthesized random line images to construct a new training sample at each tree-building step rather than using a single set of training data from which samples were drawn with replacement (\ie bootstrapping). For detection, each sample comprised 100\,000 curvilinear structure pixels and 100\,000 background pixels, while for orientation regression we used 200\,000 pixels all belonging to curvilinear structure. 

Random Forest building proceeded exactly as in the retinography experiments.

For the four learning methods (\dtcwt{}/RF, Monogenic/RF, Linop/RF, Gaussian/RF), we first constructed random forests to classify between structure and background pixels.

For any given representation (\dtcwt{}, Monogenic, Linop, Gaussian) and forest (classification, regression) we applied the following scheme:

\begin{enumerate}
\item	Generate a new synthetic line image with known ground truth
\item Extract feature vectors for a random set of pixels in the image
\item Repeat 1 and 2 until training sample complete
\item Construct tree using the CART algorithm
\item Repeat 1 to 4 until 200 trees constructed
\end{enumerate}

For all methods, the number of scales used $s$ and the neighbourhood size $w$ were empirically tested to select the best combination for each method. In each case, we tried $s$ = 3, 4, 5, 6 and $w$ = 1, 3.

\begin{itemize}
\item	\dtcwt{}/RF: images were decomposed using the \dtcwt{} to $s$ scales. Neighbourhoods of interpolated phase and magnitude coefficients were extracted in each of the 6 oriented subbands producing a feature vector of $12 \cdot w^2 \cdot s$ elements.

\item	Monogenic/RF: the monogenic signal was extracted across $s$ scales, with the initial wavelength set at $\lambda$ = 4 pixels. Neighbourhoods of phase, amplitude and orientation values were computed giving a total feature size of $6 \cdot w^2 \cdot s$. 

\item	Linop/RF: 8 oriented line filters were computed at each scale. Collecting neighbourhoods of the oriented filter responses produced $16 \cdot w^2 \cdot s$ elements in each feature vectors.

\item	Gaussian/RF: for the Gaussian 2nd derivative method, the three directional derivatives were applied to an image at each scale. The standard deviation of the smallest kernel was 1 pixel, subsequent kernels increased by a factor of 2 at each scale. As with Monogenic/RF this resulted in feature vectors with $6 \cdot w \cdot s$ elements.
\end{itemize}

For testing, feature vectors for each representation were extracted at all pixels in the 100 synthetic test images.


\subsection{Detecting Linear Structures}
In our first set of experiments, we investigate the ability of each image representation and classification method to detect the presence of a line (such as a vessel, duct or spicule) in the image. For this task, we used a binary label (present \vs{} not present) as the target we aimed to predict.

\subsubsection{Results on Synthetic Mammograms}
\input{experiments/detecting_lines/in_mammograms/exp_realmamm_detection.tex} % IPMI, IWDM

\subsubsection{Results on Real Mammograms}
\input{experiments/detecting_lines/in_mammograms/exp_synthmamm_detection.tex} % IWDM, IPMI

\subsection{Classifying Spicules}
\input{experiments/classifying_lines/in_mammograms/exp_realmamm_spicule_classification.tex}

\subsection{Estimating Orientations}
\input{experiments/measuring_orientation/in_mammograms/exp_synthmamm_orientation.tex}

These results show that the four learning methods perform significantly better than the three prescriptive methods (with the exception of orientation computation in Monogenic/RF). \dtcwt{}/RF is significantly the strongest performing for both line detection and orientation estimation, followed by Linop/RF then Gaussian/RF.

%\input{figs/fig_cumfreq_orientation_error.tex}
%\input{tab_mammogram_orientations.tex}

%\input{tab_ipmi_detection_orientation.tex}
%\input{figs/fig_synth_mammograms.tex}
%\input{figs/fig_real_mammograms.tex}


\clearpage
\section{Discussion}
\input{discussion.tex}


\clearpage
\section{Conclusions}
\input{conclusions.tex}


\section*{Acknowledgements}
We thank Nick Kingsbury for the \dtcwt{} Matlab toolbox. Mammograms were provided by the Nightingale Breast Centre, South Manchester University Hospitals Trust, UK and were annotated by Dr Caroline Boggis and Dr Rumana Rahim. This work was funded by EPSRC grant EP/E031307/1.

\bibliographystyle{plain}
\bibliography{%
./bib/_aliases,%
./bib/mobio,%
./bib/mammography,%
./bib/ml,%
./bib/nailfold,%
./bib/papers_by_year,%
./bib/local}

\end{document}